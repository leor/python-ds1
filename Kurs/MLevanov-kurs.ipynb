{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 20)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('input/train.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data to train and valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# try to use stratify\n",
    "train, valid = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 20), (2000, 20))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.corr()\n",
    "# lowest correlation: HouseYear\n",
    "# high correlation: Rooms, Square, Floor, Social_1, Social_2, Helthcare_2, Shops_1, large_district, rich_district, big_flats_district, mean_dr_price, mean_d_square, mean_d_price, mean_sqm_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_square = train['Square'].mean()\n",
    "mean_price = train['Price'].mean()\n",
    "mean_life_square = train['LifeSquare'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(df):\n",
    "    # Healthcare_1 = too much data lost\n",
    "    # LifeSquare - lots of data lost and contains lots of errors\n",
    "    # KitchenSquare - lots of errors\n",
    "    # HouseYear - errors, low correlation\n",
    "    df = df.drop(['Healthcare_1', 'KitchenSquare', 'HouseYear'], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_floor(df):\n",
    "    df.loc[df['Floor'] > df['HouseFloor'], 'Floor'] = df['HouseFloor']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_square(df, square=mean_square):\n",
    "    df.loc[df['Square'] > 250, 'Square'] = square\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_rooms(df):\n",
    "    df.loc[df['Rooms'] > 6, 'Rooms'] = 6\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_lifesquare(df):\n",
    "    df.loc[(df['LifeSquare'] < 10) & (df['Square'] > 10), 'LifeSquare'] = df.loc[(df['LifeSquare'] < 10) & (df['Square'] > 10), 'Square']*0.72\n",
    "    df.loc[df['LifeSquare'].isnull(), 'LifeSquare'] = df.loc[df['LifeSquare'].isnull(), 'Square']*0.72\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dummies(df):\n",
    "    for d in ['Shops_2', 'Ecology_2', 'Ecology_3']:\n",
    "        df[d] = (df[d] == 'A').astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sp_dr = train.groupby(['DistrictId', 'Rooms'], as_index=False)[['Square','Price']].mean().rename(columns={'Price':'mean_dr_price', 'Square': 'mean_dr_square'})\n",
    "mean_sp_d = train.groupby(['DistrictId'], as_index=False)[['Square', 'Price']].mean().rename(columns={'Price':'mean_d_price', 'Square': 'mean_d_square'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_district = pd.DataFrame((train['DistrictId'].value_counts() > 100).astype(int)).reset_index().rename(columns={'DistrictId': 'large_district', 'index': 'DistrictId'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_district = pd.DataFrame((train['Price'] > mean_price).astype(int)).reset_index().rename(columns={'Price': 'rich_district', 'index': 'DistrictId'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_flats_district = pd.DataFrame((train['Square'] > mean_square).astype(int)).reset_index().rename(columns={'Square': 'big_flats_district', 'index': 'DistrictId'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_distirct_attributes(df, large_districts=large_district, rich_districts=rich_district, big_flats=big_flats_district):\n",
    "    df = pd.merge(df, large_districts, on=['DistrictId'], how='left')\n",
    "    df['large_district'] = df['large_district'].fillna(0)\n",
    "    \n",
    "    df = pd.merge(df, rich_districts, on=['DistrictId'], how='left')\n",
    "    df['rich_district'] = df['rich_district'].fillna(0)\n",
    "    \n",
    "    df = pd.merge(df, big_flats, on=['DistrictId'], how='left')\n",
    "    df['big_flats_district'] = df['big_flats_district'].fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mean_prices(df, mean_for_dr=mean_sp_dr, mean_for_d=mean_sp_d, price=mean_price, square=mean_square):\n",
    "    df = pd.merge(df, mean_for_dr, on=['DistrictId', 'Rooms'], how='left')\n",
    "    df = pd.merge(df, mean_for_d, on=['DistrictId'], how='left')\n",
    "    \n",
    "    df['mean_dr_price'] = df['mean_dr_price'].fillna(price)\n",
    "    df['mean_d_price'] = df['mean_d_price'].fillna(df['mean_dr_price'])\n",
    "    \n",
    "    df['mean_dr_square'] = df['mean_dr_square'].fillna(price)\n",
    "    df['mean_d_square'] = df['mean_d_square'].fillna(df['mean_dr_square'])\n",
    "    \n",
    "    df['mean_sqm_price'] = df['mean_d_price'] / df['mean_d_square']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    df = clean_up(df)\n",
    "    df = fix_rooms(df)\n",
    "    df = fix_square(df)\n",
    "    df = fix_floor(df)\n",
    "    df = fix_lifesquare(df)\n",
    "    df = make_dummies(df)\n",
    "    df = add_distirct_attributes(df)\n",
    "    df = add_mean_prices(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8000 entries, 0 to 7999\n",
      "Data columns (total 25 columns):\n",
      "Id                    8000 non-null int64\n",
      "DistrictId            8000 non-null int64\n",
      "Rooms                 8000 non-null float64\n",
      "Square                8000 non-null float64\n",
      "LifeSquare            8000 non-null float64\n",
      "Floor                 8000 non-null float64\n",
      "HouseFloor            8000 non-null float64\n",
      "Ecology_1             8000 non-null float64\n",
      "Ecology_2             8000 non-null int64\n",
      "Ecology_3             8000 non-null int64\n",
      "Social_1              8000 non-null int64\n",
      "Social_2              8000 non-null int64\n",
      "Social_3              8000 non-null int64\n",
      "Helthcare_2           8000 non-null int64\n",
      "Shops_1               8000 non-null int64\n",
      "Shops_2               8000 non-null int64\n",
      "Price                 8000 non-null float64\n",
      "large_district        8000 non-null int64\n",
      "rich_district         8000 non-null float64\n",
      "big_flats_district    8000 non-null float64\n",
      "mean_dr_square        8000 non-null float64\n",
      "mean_dr_price         8000 non-null float64\n",
      "mean_d_square         8000 non-null float64\n",
      "mean_d_price          8000 non-null float64\n",
      "mean_sqm_price        8000 non-null float64\n",
      "dtypes: float64(14), int64(11)\n",
      "memory usage: 1.6 MB\n"
     ]
    }
   ],
   "source": [
    "train = prepare_data(train)\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2000 entries, 0 to 1999\n",
      "Data columns (total 25 columns):\n",
      "Id                    2000 non-null int64\n",
      "DistrictId            2000 non-null int64\n",
      "Rooms                 2000 non-null float64\n",
      "Square                2000 non-null float64\n",
      "LifeSquare            2000 non-null float64\n",
      "Floor                 2000 non-null float64\n",
      "HouseFloor            2000 non-null float64\n",
      "Ecology_1             2000 non-null float64\n",
      "Ecology_2             2000 non-null int64\n",
      "Ecology_3             2000 non-null int64\n",
      "Social_1              2000 non-null int64\n",
      "Social_2              2000 non-null int64\n",
      "Social_3              2000 non-null int64\n",
      "Helthcare_2           2000 non-null int64\n",
      "Shops_1               2000 non-null int64\n",
      "Shops_2               2000 non-null int64\n",
      "Price                 2000 non-null float64\n",
      "large_district        2000 non-null float64\n",
      "rich_district         2000 non-null float64\n",
      "big_flats_district    2000 non-null float64\n",
      "mean_dr_square        2000 non-null float64\n",
      "mean_dr_price         2000 non-null float64\n",
      "mean_d_square         2000 non-null float64\n",
      "mean_d_price          2000 non-null float64\n",
      "mean_sqm_price        2000 non-null float64\n",
      "dtypes: float64(15), int64(10)\n",
      "memory usage: 406.2 KB\n"
     ]
    }
   ],
   "source": [
    "valid = prepare_data(valid)\n",
    "valid.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feats = ['Rooms', 'Square', 'LifeSquare', 'Floor', 'Social_1', 'Social_2', 'Helthcare_2', 'large_district', 'rich_district', 'big_flats_district', 'mean_d_price', 'mean_dr_price', 'mean_dr_square', 'mean_sqm_price']\n",
    "feats = ['Rooms', 'Square', 'LifeSquare', 'Floor', 'HouseFloor', 'Social_1', 'Social_2', 'Helthcare_2', 'Shops_1', 'large_district', 'rich_district', 'big_flats_district', 'mean_d_price', 'mean_dr_price', 'mean_dr_square', 'mean_sqm_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_scaled = pd.DataFrame(scaler.fit_transform(train.loc[:, feats]), columns=feats)\n",
    "valid_scaled = pd.DataFrame(scaler.transform(valid.loc[:, feats]), columns=feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000,), (2000,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "labels_train = kmeans.fit_predict(train_scaled)\n",
    "labels_valid = kmeans.predict(valid_scaled)\n",
    "\n",
    "labels_train.shape, labels_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score as r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(model, df, target=None, evaluate='Yes'):\n",
    "    pred = model.predict(df)\n",
    "    if evaluate == 'Yes' and target is not None:\n",
    "        print('R2: %s' % r2(target, pred))\n",
    "        print('MSE: %s' % mse(target, pred))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parameters = [{'n_estimators': [150, 200, 250, 300, 350, 400], \n",
    "               'max_features': np.arange(5, 13),\n",
    "               'max_depth': np.arange(7, 10)}]\n",
    "\n",
    "clf = GridSearchCV(estimator=RandomForestRegressor(random_state=42),\n",
    "                  param_grid=parameters,\n",
    "                  scoring='r2',\n",
    "                  cv=5)\n",
    "\n",
    "\n",
    "def get_best_params(clf, df, target, labels, cluster_count=2):\n",
    "    best = {}\n",
    "    for i in range(0, cluster_count):\n",
    "        clf.fit(df[labels==i], target[labels==i])\n",
    "        print('Best params for %d:' % i, clf.best_params_)\n",
    "        best[i] = clf.best_params_\n",
    "        \n",
    "    return best\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_best(best, df, target, labels, cluster_count=2):\n",
    "    result = {}\n",
    "    for i in best:\n",
    "        b = RandomForestRegressor(random_state=42, **best[i])\n",
    "        b.fit(df[labels==i], target[labels==i])\n",
    "        result[i] = b\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_scaled[labels_train==2].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params = get_best_params(clf, df=train_scaled, target=train['Price'], labels=labels_train, cluster_count=3)\n",
    "best_params = {\n",
    "    0: {'max_depth': 9, 'max_features': 7, 'n_estimators': 400},\n",
    "    1: {'max_depth': 7, 'max_features': 6, 'n_estimators': 350},\n",
    "    2: {'max_depth': 9, 'max_features': 6, 'n_estimators': 150}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = train_best(best_params, df=train_scaled, target=train['Price'], labels=labels_train, cluster_count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.8964200459905027\n",
      "MSE: 267570120.17949018\n",
      "R2: 0.6976043376025217\n",
      "MSE: 3218469376.307418\n",
      "R2: 0.7332466151466923\n",
      "MSE: 691171823.3908111\n"
     ]
    }
   ],
   "source": [
    "train_pred = {}\n",
    "for i in best_models:\n",
    "    train_pred[i] = get_prediction(best_models[i], train_scaled[labels_train==i], train['Price'][labels_train==i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for all Train: 0.8625470416383223\n"
     ]
    }
   ],
   "source": [
    "train_all = np.hstack([train['Price'][labels_train==i] for i in best_models])\n",
    "train_pred_all = np.hstack(train_pred.values())\n",
    "\n",
    "print('R2 for all Train: %s' % r2(train_all, train_pred_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.7612444792814325\n",
      "MSE: 712582230.034672\n",
      "R2: 0.33417529831156056\n",
      "MSE: 7594597988.284365\n",
      "R2: 0.46192823050051435\n",
      "MSE: 1583655190.9477704\n"
     ]
    }
   ],
   "source": [
    "valid_pred = {}\n",
    "for i in best_models:\n",
    "    valid_pred[i] = get_prediction(best_models[i], valid_scaled[labels_valid==i], valid['Price'][labels_valid==i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for all Valid: 0.6869213452217804\n"
     ]
    }
   ],
   "source": [
    "valid_all = np.hstack([valid['Price'][labels_valid==i] for i in best_models])\n",
    "valid_pred_all = np.hstack(valid_pred.values())\n",
    "\n",
    "print('R2 for all Valid: %s' % r2(valid_all, valid_pred_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 19)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('input/test.csv')\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test = prepare_data(test)\n",
    "test_scaled = pd.DataFrame(scaler.transform(test.loc[:, feats]), columns=feats)\n",
    "labels_test = kmeans.predict(test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in best_models:\n",
    "    test.loc[labels_test==i, 'Price'] = get_prediction(best_models[i], test_scaled[labels_test==i], target=None, evaluate='No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      5000.000000\n",
       "mean     214122.818134\n",
       "std       76701.297964\n",
       "min       68112.650300\n",
       "25%      164658.199929\n",
       "50%      195968.207157\n",
       "75%      247418.179068\n",
       "max      560870.822370\n",
       "Name: Price, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[:, ['Id', 'Price']].to_csv('MLevanov_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_check = pd.read_csv('MLevanov_predictions.csv')\n",
    "test_check.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Price'], dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_check.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
